{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Accuracy Calculation",
        "",
        "This notebook:",
        "1. Loads **shared** ground truth from `output/ground_truth/` (generated by Step 1)",
        "2. Loads LLM predictions from Step 2 (`set1_llm_output.csv`, `set2_llm_output.csv`)",
        "3. Compares Set 1 (A4-A7) and Set 2 (B4-B7) predictions against ground truth",
        "4. Calculates accuracy metrics (exact-match recall and Jaccard)",
        "",
        "**Prerequisites**: Run `step1_ground_truth.ipynb` (in `ground_truth/`) and `step2_llm_queries.ipynb` (in this folder) first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================\n",
        "# Path Configuration\n",
        "# ============================================================\n",
        "\n",
        "_cwd = Path(\".\").resolve()\n",
        "if _cwd.name.startswith(\"testing_\"):\n",
        "    REPO_ROOT = _cwd.parent\n",
        "    LLM_NAME = _cwd.name.replace(\"testing_\", \"\")\n",
        "else:\n",
        "    REPO_ROOT = _cwd\n",
        "    LLM_NAME = \"gpt\"\n",
        "\n",
        "OUTPUT_ROOT = (REPO_ROOT / \"output\").resolve()\n",
        "PIPELINE_ROOT = OUTPUT_ROOT / LLM_NAME\n",
        "\n",
        "# Shared ground truth\n",
        "GT_ROOT = OUTPUT_ROOT / \"ground_truth\"\n",
        "GT_PATH = GT_ROOT / \"ground_truth.csv\"\n",
        "\n",
        "# Find the LATEST run directory for this LLM\n",
        "run_dirs = sorted([d for d in PIPELINE_ROOT.iterdir() if d.is_dir() and d.name.startswith(\"run_\")])\n",
        "if not run_dirs:\n",
        "    raise FileNotFoundError(\"No run directories found. Run step2_llm_queries.ipynb first.\")\n",
        "RUN_DIR = run_dirs[-1]\n",
        "\n",
        "# LLM prediction files\n",
        "SET1_PATH = RUN_DIR / \"step2_llm_set1\" / \"set1_llm_output.csv\"\n",
        "SET2_PATH = RUN_DIR / \"step2_llm_set2\" / \"set2_llm_output.csv\"\n",
        "\n",
        "# Output directory\n",
        "STEP3_DIR = RUN_DIR / \"step3_accuracy\"\n",
        "STEP3_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Output files\n",
        "OUT_COMPARE_PATH = STEP3_DIR / \"comparison_set1_set2_vs_ground_truth.csv\"\n",
        "\n",
        "# Verify prerequisites\n",
        "assert GT_PATH.exists(), f\"Ground truth not found: {GT_PATH}\\nRun step1_ground_truth.ipynb in ground_truth/ first.\"\n",
        "assert SET1_PATH.exists(), f\"Set 1 predictions not found: {SET1_PATH}\\nRun step2_llm_queries.ipynb first.\"\n",
        "assert SET2_PATH.exists(), f\"Set 2 predictions not found: {SET2_PATH}\\nRun step2_llm_queries.ipynb first.\"\n",
        "\n",
        "print(\"RUN_DIR:\", RUN_DIR)\n",
        "print(\"GT (shared):\", GT_PATH)\n",
        "print(\"Set 1:\", SET1_PATH)\n",
        "print(\"Set 2:\", SET2_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Helpers: normalization and accuracy\n",
        "# ============================================================\n",
        "\n",
        "def strip_semantic_tag(term: str) -> str:\n",
        "    return re.sub(r\"\\s*\\([^()]*\\)\\s*$\", \"\", term or \"\").strip()\n",
        "\n",
        "def normalize_term(term: str) -> str:\n",
        "    term = (term or \"\").lower().strip()\n",
        "    term = re.sub(r\"\\s+\", \" \", term)\n",
        "    term = strip_semantic_tag(term)\n",
        "    return term\n",
        "\n",
        "def pipe_to_set(s: str):\n",
        "    if not s:\n",
        "        return set()\n",
        "    s = str(s).strip()\n",
        "    if not s or s.upper() == \"UNKNOWN\":\n",
        "        return set()\n",
        "    return {\n",
        "        normalize_term(x)\n",
        "        for x in s.split(\"|\")\n",
        "        if x.strip() and x.upper() != \"UNKNOWN\"\n",
        "    }\n",
        "\n",
        "def accuracy_exact_match(gt_set: set, pred_set: set) -> float:\n",
        "    \"\"\"Exact-match (recall): |GT & pred| / |GT| when |GT| > 0, else 0.\"\"\"\n",
        "    if len(gt_set) == 0:\n",
        "        return 0.0\n",
        "    return len(gt_set & pred_set) / len(gt_set)\n",
        "\n",
        "def accuracy_jaccard(gt_set: set, pred_set: set) -> float:\n",
        "    \"\"\"Jaccard: |GT & pred| / |GT | pred| when union > 0; 0 when GT empty.\"\"\"\n",
        "    if len(gt_set) == 0:\n",
        "        return 0.0\n",
        "    union = gt_set | pred_set\n",
        "    if len(union) == 0:\n",
        "        return 0.0\n",
        "    return len(gt_set & pred_set) / len(union)\n",
        "\n",
        "print(\"Helpers loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Ground Truth and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Load ground truth\n",
        "# ============================================================\n",
        "gt_df = pd.read_csv(GT_PATH, dtype=str).fillna(\"\")\n",
        "print(f\"Ground truth: {len(gt_df)} concepts from {GT_PATH}\")\n",
        "\n",
        "gt_map = gt_df.set_index(\"concept_term\").to_dict(orient=\"index\")\n",
        "concepts = gt_df[\"concept_term\"].tolist()\n",
        "\n",
        "# ============================================================\n",
        "# Load Set 1 / Set 2 LLM predictions\n",
        "# ============================================================\n",
        "set1 = pd.read_csv(SET1_PATH, dtype=str).fillna(\"\")\n",
        "set2 = pd.read_csv(SET2_PATH, dtype=str).fillna(\"\")\n",
        "\n",
        "set1_idx = set1.set_index(\"concept_term\") if \"concept_term\" in set1.columns else pd.DataFrame().set_index(pd.Index([]))\n",
        "set2_idx = set2.set_index(\"concept_term\") if \"concept_term\" in set2.columns else pd.DataFrame().set_index(pd.Index([]))\n",
        "\n",
        "# Ensure prediction columns exist\n",
        "# Set 1: A4_parents, A5_grandparents, A6_children, A7_siblings\n",
        "for col in [\"A4_parents\", \"A5_grandparents\", \"A6_children\", \"A7_siblings\"]:\n",
        "    if col not in set1.columns:\n",
        "        set1[col] = \"\"\n",
        "# Set 2: B4_immediate_broader, B5_grandparents, B6_immediate_narrower, B7_peer_terms\n",
        "for col in [\"B4_immediate_broader\", \"B5_grandparents\", \"B6_immediate_narrower\", \"B7_peer_terms\"]:\n",
        "    if col not in set2.columns:\n",
        "        set2[col] = \"\"\n",
        "\n",
        "print(f\"Set 1 predictions: {len(set1)} rows\")\n",
        "print(f\"Set 2 predictions: {len(set2)} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Predictions vs Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Compare predictions vs ground truth\n",
        "# ============================================================\n",
        "\n",
        "rows = []\n",
        "\n",
        "for concept_term in concepts:\n",
        "    gt_row = gt_map.get(concept_term, {})\n",
        "\n",
        "    gt_id = str(gt_row.get(\"snomed_id\", \"\"))\n",
        "    gt_fsn = str(gt_row.get(\"fsn\", \"\"))\n",
        "\n",
        "    gt_parents_pipe      = str(gt_row.get(\"parents\", \"\"))\n",
        "    gt_grandparents_pipe = str(gt_row.get(\"grandparents\", \"\"))\n",
        "    gt_children_pipe     = str(gt_row.get(\"children\", \"\"))\n",
        "    gt_siblings_pipe     = str(gt_row.get(\"siblings\", \"\"))\n",
        "\n",
        "    gt_parents_set      = pipe_to_set(gt_parents_pipe)\n",
        "    gt_grandparents_set = pipe_to_set(gt_grandparents_pipe)\n",
        "    gt_children_set     = pipe_to_set(gt_children_pipe)\n",
        "    gt_siblings_set     = pipe_to_set(gt_siblings_pipe)\n",
        "\n",
        "    # Pull Set 1 predictions (A4=parents, A5=grandparents, A6=children, A7=siblings)\n",
        "    if concept_term in set1_idx.index:\n",
        "        s1_row = set1_idx.loc[concept_term]\n",
        "        s1_A4 = str(s1_row.get(\"A4_parents\", \"\"))\n",
        "        s1_A5 = str(s1_row.get(\"A5_grandparents\", \"\"))\n",
        "        s1_A6 = str(s1_row.get(\"A6_children\", \"\"))\n",
        "        s1_A7 = str(s1_row.get(\"A7_siblings\", \"\"))\n",
        "    else:\n",
        "        s1_A4 = s1_A5 = s1_A6 = s1_A7 = \"\"\n",
        "\n",
        "    # Pull Set 2 predictions (B4=broader/parents, B5=grandparents, B6=narrower/children, B7=peers/siblings)\n",
        "    if concept_term in set2_idx.index:\n",
        "        s2_row = set2_idx.loc[concept_term]\n",
        "        s2_B4 = str(s2_row.get(\"B4_immediate_broader\", \"\"))\n",
        "        s2_B5 = str(s2_row.get(\"B5_grandparents\", \"\"))\n",
        "        s2_B6 = str(s2_row.get(\"B6_immediate_narrower\", \"\"))\n",
        "        s2_B7 = str(s2_row.get(\"B7_peer_terms\", \"\"))\n",
        "    else:\n",
        "        s2_B4 = s2_B5 = s2_B6 = s2_B7 = \"\"\n",
        "\n",
        "    # Prediction sets - Set 1\n",
        "    s1_parents_set      = pipe_to_set(s1_A4)\n",
        "    s1_grandparents_set = pipe_to_set(s1_A5)\n",
        "    s1_children_set     = pipe_to_set(s1_A6)\n",
        "    s1_siblings_set     = pipe_to_set(s1_A7)\n",
        "\n",
        "    # Prediction sets - Set 2\n",
        "    s2_parents_set      = pipe_to_set(s2_B4)\n",
        "    s2_grandparents_set = pipe_to_set(s2_B5)\n",
        "    s2_children_set     = pipe_to_set(s2_B6)\n",
        "    s2_siblings_set     = pipe_to_set(s2_B7)\n",
        "\n",
        "    # ---- Set 1 accuracy ----\n",
        "    s1_p_exact  = accuracy_exact_match(gt_parents_set, s1_parents_set)\n",
        "    s1_gp_exact = accuracy_exact_match(gt_grandparents_set, s1_grandparents_set)\n",
        "    s1_c_exact  = accuracy_exact_match(gt_children_set, s1_children_set)\n",
        "    s1_s_exact  = accuracy_exact_match(gt_siblings_set, s1_siblings_set)\n",
        "    s1_parents_j      = accuracy_jaccard(gt_parents_set, s1_parents_set)\n",
        "    s1_grandparents_j = accuracy_jaccard(gt_grandparents_set, s1_grandparents_set)\n",
        "    s1_children_j     = accuracy_jaccard(gt_children_set, s1_children_set)\n",
        "    s1_siblings_j     = accuracy_jaccard(gt_siblings_set, s1_siblings_set)\n",
        "    s1_concept_exact   = (s1_p_exact + s1_gp_exact + s1_c_exact + s1_s_exact) / 4.0\n",
        "    s1_concept_jaccard = (s1_parents_j + s1_grandparents_j + s1_children_j + s1_siblings_j) / 4.0\n",
        "\n",
        "    # ---- Set 2 accuracy ----\n",
        "    s2_p_exact  = accuracy_exact_match(gt_parents_set, s2_parents_set)\n",
        "    s2_gp_exact = accuracy_exact_match(gt_grandparents_set, s2_grandparents_set)\n",
        "    s2_c_exact  = accuracy_exact_match(gt_children_set, s2_children_set)\n",
        "    s2_s_exact  = accuracy_exact_match(gt_siblings_set, s2_siblings_set)\n",
        "    s2_parents_j      = accuracy_jaccard(gt_parents_set, s2_parents_set)\n",
        "    s2_grandparents_j = accuracy_jaccard(gt_grandparents_set, s2_grandparents_set)\n",
        "    s2_children_j     = accuracy_jaccard(gt_children_set, s2_children_set)\n",
        "    s2_siblings_j     = accuracy_jaccard(gt_siblings_set, s2_siblings_set)\n",
        "    s2_concept_exact   = (s2_p_exact + s2_gp_exact + s2_c_exact + s2_s_exact) / 4.0\n",
        "    s2_concept_jaccard = (s2_parents_j + s2_grandparents_j + s2_children_j + s2_siblings_j) / 4.0\n",
        "\n",
        "    rows.append({\n",
        "        \"concept_name\": concept_term,\n",
        "        \"gt_snomed_id\": gt_id,\n",
        "        \"gt_fsn\": gt_fsn,\n",
        "\n",
        "        \"gt_parents\": gt_parents_pipe,\n",
        "        \"gt_grandparents\": gt_grandparents_pipe,\n",
        "        \"gt_children\": gt_children_pipe,\n",
        "        \"gt_siblings\": gt_siblings_pipe,\n",
        "\n",
        "        \"set1_parents\": s1_A4,\n",
        "        \"set1_grandparents\": s1_A5,\n",
        "        \"set1_children\": s1_A6,\n",
        "        \"set1_siblings\": s1_A7,\n",
        "\n",
        "        \"set1_parents_exact\": s1_p_exact,\n",
        "        \"set1_grandparents_exact\": s1_gp_exact,\n",
        "        \"set1_children_exact\": s1_c_exact,\n",
        "        \"set1_siblings_exact\": s1_s_exact,\n",
        "        \"set1_concept_exact\": s1_concept_exact,\n",
        "        \"set1_parents_jaccard\": s1_parents_j,\n",
        "        \"set1_grandparents_jaccard\": s1_grandparents_j,\n",
        "        \"set1_children_jaccard\": s1_children_j,\n",
        "        \"set1_siblings_jaccard\": s1_siblings_j,\n",
        "        \"set1_concept_jaccard\": s1_concept_jaccard,\n",
        "\n",
        "        \"set2_parents\": s2_B4,\n",
        "        \"set2_grandparents\": s2_B5,\n",
        "        \"set2_children\": s2_B6,\n",
        "        \"set2_siblings\": s2_B7,\n",
        "\n",
        "        \"set2_parents_exact\": s2_p_exact,\n",
        "        \"set2_grandparents_exact\": s2_gp_exact,\n",
        "        \"set2_children_exact\": s2_c_exact,\n",
        "        \"set2_siblings_exact\": s2_s_exact,\n",
        "        \"set2_concept_exact\": s2_concept_exact,\n",
        "        \"set2_parents_jaccard\": s2_parents_j,\n",
        "        \"set2_grandparents_jaccard\": s2_grandparents_j,\n",
        "        \"set2_children_jaccard\": s2_children_j,\n",
        "        \"set2_siblings_jaccard\": s2_siblings_j,\n",
        "        \"set2_concept_jaccard\": s2_concept_jaccard,\n",
        "    })\n",
        "\n",
        "out_df = pd.DataFrame(rows)\n",
        "out_df.to_csv(OUT_COMPARE_PATH, index=False)\n",
        "\n",
        "print(f\"Wrote comparison: {OUT_COMPARE_PATH}\")\n",
        "print(out_df[[\"concept_name\", \"gt_snomed_id\", \"gt_fsn\"]].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy Summary Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Table 1 - Exact-match (recall): average per field and overall\n",
        "# ============================================================\n",
        "\n",
        "table_exact = pd.DataFrame([\n",
        "    {\"metric\": \"parents\",       \"set1_avg\": round(100 * out_df[\"set1_parents_exact\"].mean(), 2),       \"set2_avg\": round(100 * out_df[\"set2_parents_exact\"].mean(), 2)},\n",
        "    {\"metric\": \"grandparents\",  \"set1_avg\": round(100 * out_df[\"set1_grandparents_exact\"].mean(), 2),  \"set2_avg\": round(100 * out_df[\"set2_grandparents_exact\"].mean(), 2)},\n",
        "    {\"metric\": \"children\",      \"set1_avg\": round(100 * out_df[\"set1_children_exact\"].mean(), 2),      \"set2_avg\": round(100 * out_df[\"set2_children_exact\"].mean(), 2)},\n",
        "    {\"metric\": \"siblings\",      \"set1_avg\": round(100 * out_df[\"set1_siblings_exact\"].mean(), 2),      \"set2_avg\": round(100 * out_df[\"set2_siblings_exact\"].mean(), 2)},\n",
        "    {\"metric\": \"overall_avg\",   \"set1_avg\": round(100 * out_df[\"set1_concept_exact\"].mean(), 2),       \"set2_avg\": round(100 * out_df[\"set2_concept_exact\"].mean(), 2)},\n",
        "])\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TABLE 1 - Exact-match (recall, %)\")\n",
        "print(\"=\" * 80)\n",
        "print(table_exact.to_string(index=False))\n",
        "\n",
        "# ============================================================\n",
        "# Table 2 - Jaccard: average per field and overall\n",
        "# ============================================================\n",
        "\n",
        "table_jaccard = pd.DataFrame([\n",
        "    {\"metric\": \"parents\",       \"set1_avg\": round(100 * out_df[\"set1_parents_jaccard\"].mean(), 2),       \"set2_avg\": round(100 * out_df[\"set2_parents_jaccard\"].mean(), 2)},\n",
        "    {\"metric\": \"grandparents\",  \"set1_avg\": round(100 * out_df[\"set1_grandparents_jaccard\"].mean(), 2),  \"set2_avg\": round(100 * out_df[\"set2_grandparents_jaccard\"].mean(), 2)},\n",
        "    {\"metric\": \"children\",      \"set1_avg\": round(100 * out_df[\"set1_children_jaccard\"].mean(), 2),      \"set2_avg\": round(100 * out_df[\"set2_children_jaccard\"].mean(), 2)},\n",
        "    {\"metric\": \"siblings\",      \"set1_avg\": round(100 * out_df[\"set1_siblings_jaccard\"].mean(), 2),      \"set2_avg\": round(100 * out_df[\"set2_siblings_jaccard\"].mean(), 2)},\n",
        "    {\"metric\": \"overall_avg\",   \"set1_avg\": round(100 * out_df[\"set1_concept_jaccard\"].mean(), 2),       \"set2_avg\": round(100 * out_df[\"set2_concept_jaccard\"].mean(), 2)},\n",
        "])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TABLE 2 - Jaccard (%)\")\n",
        "print(\"=\" * 80)\n",
        "print(table_jaccard.to_string(index=False))\n",
        "print(\"\\nStep 3 (Accuracy) complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}